\chapter{Conclusion}

The first attempt to parallelize the program using the \textit{for} offered bad results. This is not linked to the use of OpenMP as the Pthread implementation of the same algorithm gives similar results. As explained earlier, the results are bad because of the overhead created by spawning and joining the threads for each iteration of the outermost loop. It then requires a consequent amount of data to justify the use of threads and get some speedup. So, this way of parallelizing programs is not adapted to that kind of problems where the nested loops only can be parallelized as it generates a huge amount of overhead.\\ 

Concerning the \textit{task} directive, we can say that it is a directive that should be reserved for usage in some special circumstances where the other way of parallelizing the program cannot apply (or hardly). Indeed, the program has to justify the great overheads generated by the use of tasks. To do that, the amount of data to treat must be big enough as well.\\

A potential source of inefficiency with OpenMP is that the compiler takes care of the parallelism and thread synchronization through the use of pragma. If this is very easy to understand and use, it has also to be very generic. Hence, very specific problems can suffer from this genericity. To avoid this pitfall, OpenMP offers the possibility to the user to define his own way to synchronize the threads using locks. A programmer can then use this feature to write a code specific to his problem but that gives very good results. 
